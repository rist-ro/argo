import numbers
import tensorflow as tf
from tensorflow.python.ops.parallel_for.gradients import batch_jacobian

import numpy as np


import importlib

# from https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/contrib/layers/python/layers/regularizers.py

def ring_loss_regularizer(scale, scope=None):
    # Returns a dictionary of functions that can be used to compute the regularizations
    # to the mean and covariance generated by a gaussian stochastic encoder

    # x is input to the network

    # input validation
    if isinstance(scale, numbers.Integral):
        raise ValueError('scale cannot be an integer: %s' % scale)
    if isinstance(scale, numbers.Real):
        if scale < 0.:
            raise ValueError('Setting a scale less than 0 on a regularizer: %g' %
scale)

    use_pfor = False

    def contractive_regularizer(mean, cov, x, name=None):
        with tf.name_scope(scope, 'contractive_regularizer', [mean, cov, x]) as name:

            # scale_m = tf.convert_to_tensor(scale_mean,
            #                                dtype=mean.dtype.base_dtype,
            #                                name='scale_mean')
            #
            # scale_c = tf.convert_to_tensor(scale_covariance,
            #                                dtype=cov.dtype.base_dtype,
            #                                name='scale_covariance')
            #
            # reg_mean_node = tf.multiply(scale_m,
            #                             tf.reduce_sum(tf.abs(mean)))
            #
            # reg_cov_node = tf.multiply(scale_c,
            #                            tf.reduce_sum(tf.abs(cov)))

            scale_p = tf.convert_to_tensor(scale,
                                            dtype=mean.dtype.base_dtype,
                                            name='scale_penalty')
            
            latent_size = tf.cast(mean.shape[1], tf.float32) 
            D_total = tf.reduce_mean((tf.norm(mean, axis = 1) - tf.sqrt(latent_size))**2)
            
            reg_D_node = tf.multiply(scale_p,
                                        D_total,
                                        name=name)

            return reg_D_node

    return contractive_regularizer



def ring_loss_variable_regularizer(scale, scope=None):
    # Returns a dictionary of functions that can be used to compute the regularizations
    # to the mean and covariance generated by a gaussian stochastic encoder

    # x is input to the network

    # input validation
    if isinstance(scale, numbers.Integral):
        raise ValueError('scale cannot be an integer: %s' % scale)
    if isinstance(scale, numbers.Real):
        if scale < 0.:
            raise ValueError('Setting a scale less than 0 on a regularizer: %g' %
scale)

    use_pfor = False

    def contractive_regularizer(mean, cov, x, name=None):
        with tf.name_scope(scope, 'contractive_regularizer', [mean, cov, x]) as name:

            # scale_m = tf.convert_to_tensor(scale_mean,
            #                                dtype=mean.dtype.base_dtype,
            #                                name='scale_mean')
            #
            # scale_c = tf.convert_to_tensor(scale_covariance,
            #                                dtype=cov.dtype.base_dtype,
            #                                name='scale_covariance')
            #
            # reg_mean_node = tf.multiply(scale_m,
            #                             tf.reduce_sum(tf.abs(mean)))
            #
            # reg_cov_node = tf.multiply(scale_c,
            #                            tf.reduce_sum(tf.abs(cov)))

            scale_p = tf.convert_to_tensor(scale,
                                            dtype=mean.dtype.base_dtype,
                                            name='scale_penalty')
            
            latent_size = tf.cast(mean.shape[1], tf.float32) 
#             import pdb;pdb.set_trace()
            reference_norm = tf.get_variable("ref_norm", initializer=tf.sqrt(latent_size), dtype=tf.float32, trainable=True)
            D_total = tf.reduce_mean((tf.norm(mean, axis = 1) - reference_norm)**2)
            
            reg_D_node = tf.multiply(scale_p,
                                        D_total,
                                        name=name)

            return reg_D_node

    return contractive_regularizer


def wasserstein_contractive_regularizer(scale, scope=None):
    # Returns a dictionary of functions that can be used to compute the regularizations
    # to the mean and covariance generated by a gaussian stochastic encoder

    # x is input to the network

    # input validation
    if isinstance(scale, numbers.Integral):
        raise ValueError('scale cannot be an integer: %s' % scale)
    if isinstance(scale, numbers.Real):
        if scale < 0.:
            raise ValueError('Setting a scale less than 0 on a regularizer: %g' % scale)

    use_pfor = False
    parallel_iterations = None

    def contractive_regularizer(mean, cov, x, name=None):
        with tf.name_scope(scope, 'contractive_regularizer', [mean, cov, x]) as name:

            # scale_m = tf.convert_to_tensor(scale_mean,
            #                                dtype=mean.dtype.base_dtype,
            #                                name='scale_mean')
            #
            # scale_c = tf.convert_to_tensor(scale_covariance,
            #                                dtype=cov.dtype.base_dtype,
            #                                name='scale_covariance')
            #
            # reg_mean_node = tf.multiply(scale_m,
            #                             tf.reduce_sum(tf.abs(mean)))
            #
            # reg_cov_node = tf.multiply(scale_c,
            #                            tf.reduce_sum(tf.abs(cov)))

            scale_p = tf.convert_to_tensor(scale,
                                            dtype=mean.dtype.base_dtype,
                                            name='scale_penalty')

            #import pdb;pdb.set_trace()
            jac_mean_rk5 = batch_jacobian(mean, x, parallel_iterations = parallel_iterations, use_pfor = use_pfor) # this has shape (?, latent_size, 28, 28, 1)

            jac_shape = jac_mean_rk5.shape

            lastdim = np.prod(jac_shape[2:])
            jac_mean = tf.reshape(jac_mean_rk5, [-1, jac_shape[1], lastdim]) # obtain shape (?, latent_size, 784)

            jac_cov_rk5 = batch_jacobian(cov, x, use_pfor = use_pfor)            
            jac_cov = tf.reshape(jac_cov_rk5, [-1, jac_shape[1], lastdim]) # jac_mean_rk5 and jac_cov_rk5 have same shape: jac_shape = (?, latent_size, 28, 28, 1)

            # fisher_mean_vector = tf.ones(shape = tf.shape(cov)) # obtain constant vector 1
            # D_mean = tf.linalg.trace(tf.matmul(tf.transpose(jac_mean, perm = [0,2,1]),
            #                          tf.math.multiply(tf.expand_dims(fisher_mean_vector, axis = -1), jac_mean)))
            D_mean = tf.reduce_sum(jac_mean**2, axis=[1,2])

            fisher_cov_vector = (1/4) * (1/cov) #tf.math.pow(cov, tf.constant(-1.0)) # obtain 1/(4*sigma_k^2)

            # D_cov = tf.linalg.trace(tf.matmul(tf.transpose(jac_cov, perm=[0, 2, 1]),
            #                                   tf.math.multiply(tf.expand_dims(fisher_cov_vector, axis=-1), jac_cov)))

            D_cov = tf.reduce_sum(
                    tf.multiply(jac_cov, tf.multiply(tf.expand_dims(fisher_cov_vector, axis=-1), jac_cov)),
                    axis=[1,2]
                    )

            D_total = tf.reduce_mean(D_mean + D_cov)

            reg_D_node = tf.multiply(scale_p,
                                        D_total,
                                        name=name)

            return reg_D_node

    return contractive_regularizer


def geometric_contractive_regularizer(scale, scope=None):
    # Returns a dictionary of functions that can be used to compute the regularizations
    # to the mean and covariance generated by a gaussian stochastic encoder

    # x is input to the network

    # input validation
    if isinstance(scale, numbers.Integral):
        raise ValueError('scale cannot be an integer: %s' % scale)
    if isinstance(scale, numbers.Real):
        if scale < 0.:
            raise ValueError('Setting a scale less than 0 on a regularizer: %g' % scale)
            
    use_pfor = False
            
    def contractive_regularizer(mean, cov, x, name=None):
        with tf.name_scope(scope, 'contractive_regularizer', [mean, cov, x]) as name:

            #<<<<<<< HEAD
            # scale_m = tf.convert_to_tensor(scale_mean,
            #                                dtype=mean.dtype.base_dtype,
            #                                name='scale_mean')
            #
            # scale_c = tf.convert_to_tensor(scale_covariance,
            #                                dtype=cov.dtype.base_dtype,
            #                                name='scale_covariance')
            #
            # reg_mean_node = tf.multiply(scale_m,
            #                             tf.reduce_sum(tf.abs(mean)))
            #
            # reg_cov_node = tf.multiply(scale_c,
            #                            tf.reduce_sum(tf.abs(cov)))
            #=======
            scale_p = tf.convert_to_tensor(scale,
                                            dtype=mean.dtype.base_dtype,
                                            name='scale_penalty')


#             import pdb;pdb.set_trace()
            jac_mean_rk5 = batch_jacobian(mean, x, use_pfor = use_pfor) # this has shape (?, latent_size, 28, 28, 1)


            jac_shape = jac_mean_rk5.shape
            lastdim = np.prod(jac_shape[2:])
            jac_mean = tf.reshape(jac_mean_rk5, [-1, jac_shape[1], lastdim]) # obtain shape (?, latent_size, 784)


            jac_cov_rk5 = batch_jacobian(cov, x, use_pfor = use_pfor)

            jac_cov = tf.reshape(jac_cov_rk5, [-1, jac_shape[1], lastdim]) # jac_mean_rk5 and jac_cov_rk5 have same shape: jac_shape = (?, latent_size, 28, 28, 1)

            fisher_mean_vector = 1/cov # tf.math.pow(cov, tf.constant(-1.0)) # obtain 1/sigma_k^2
            # D_mean = tf.linalg.trace(tf.matmul(tf.transpose(jac_mean, perm = [0,2,1]),
            #                          tf.math.multiply(tf.expand_dims(fisher_mean_vector, axis = -1), jac_mean)))
            D_mean = tf.reduce_sum(
                    tf.multiply(jac_mean, tf.multiply(tf.expand_dims(fisher_mean_vector, axis=-1), jac_mean)),
                    axis=[1,2]
                    )


            fisher_cov_vector = (1/2) * (1/(cov**2))     #* tf.math.pow(cov, tf.constant(-2.0)) # obtain 1/(2*sigma_k^4)
            # D_cov = tf.linalg.trace(tf.matmul(tf.transpose(jac_cov, perm = [0,2,1]),
            #                         tf.math.multiply(tf.expand_dims(fisher_cov_vector, axis = -1), jac_cov)))

            D_cov = tf.reduce_sum(
                    tf.multiply(jac_cov, tf.multiply(tf.expand_dims(fisher_cov_vector, axis=-1), jac_cov)),
                    axis=[1,2]
                    )

            D_total = tf.reduce_mean(D_mean + D_cov)
            
            reg_D_node = tf.multiply(scale_p,
                                        D_total,
                                        name=name)

            return reg_D_node

    return contractive_regularizer


def standard_contractive_regularizer(scale_mean, scale_covariance, batch_size=1000, while_loop=False, use_pfor=False, swap_memory=False, parallel_iterations=1, trick=False, scope=None):
#def standard_contractive_regularizer(scale_mean, scale_covariance, norm, trick=False, scope=None):

    # Returns a dictionary of functions that can be used to compute the regularizations
    # to the mean and covariance generated by the encoder

    # x is input to the network

    # input validation
    if isinstance(scale_mean, numbers.Integral):
        raise ValueError('scale_mean cannot be an integer: %s' % scale_mean)

    # input validation
    if isinstance(scale_covariance, numbers.Integral):
        raise ValueError('scale_covariance cannot be an integer: %s' % scale_covariance)

    #use_pfor = False # if you change this, please notify Luigi

    def contractive_regularizer(mean, cov, x, name=None):
        with tf.name_scope(scope, 'contractive_regularizer', [mean, cov, x]) as name:
            scale_m = tf.convert_to_tensor(scale_mean,
                                         dtype=mean.dtype.base_dtype,
                                         name='scale_mean')

            scale_c = tf.convert_to_tensor(scale_covariance,
                                         dtype=cov.dtype.base_dtype,
                                         name='scale_covariance')


            # if while_loop:
            #     norm_jac_mean = tf.constant(0.0)
            #     norm_jac_cov = tf.constant(0.0)
            #     i = tf.constant(0)
            #     n_vars = tf.shape(mean)[1]
            #
            #     def cond(i, n_vars, norm_jac_mean, norm_jac_cov):
            #         return tf.less(i, n_vars)
            #
            #     def body(i, n_vars, norm_jac_mean, norm_jac_cov):
            #         #pdb.set_trace()
            #         norm_jac_mean += tf.pow(tf.norm(batch_jacobian(mean[:,i:i+batch_size], x, use_pfor = use_pfor), ord = norm), norm)
            #         norm_jac_cov += tf.pow(tf.norm(batch_jacobian(cov[:,i:i+batch_size], x, use_pfor = use_pfor), ord = norm), norm)
            #         return [tf.add(i, batch_size), n_vars, norm_jac_mean, norm_jac_cov]
            #
            #     _, _, norm_jac_mean, norm_jac_cov = tf.while_loop(cond,
            #                                                       body,
            #                                                       [i, n_vars, norm_jac_mean, norm_jac_cov],
            #                                                       #back_prop=True,
            #                                                       swap_memory=swap_memory,
            #                                                       parallel_iterations=parallel_iterations)
            #     norm_jac_mean = tf.pow(norm_jac_mean, 1/norm, name = "norm_jac_mean")
            #     norm_jac_cov = tf.pow(norm_jac_cov, 1/norm, name = "norm_jac_cov")

            # else:

            # norm_jac_mean = tf.math.pow(tf.norm(batch_jacobian(mean, x, use_pfor = use_pfor), ord = norm, name = "norm_jac_mean"), 2)
            # norm_jac_cov = tf.math.pow(tf.norm(batch_jacobian(cov, x, use_pfor = use_pfor), ord = norm, name = "norm_jac_cov"), 2)

            jac_mean = batch_jacobian(mean, x, use_pfor = use_pfor)   # this has shape [?, latent_size, 28, 28, 1]
            jac_mean_rk2 = tf.reshape(jac_mean, [tf.shape(jac_mean)[0], -1])  # this has shape [?, latent_size*28*28*1]
            # norm_jac_mean = tf.reduce_mean(tf.pow(tf.norm(jac_mean_rk2, axis = 1, name = "norm_jac_mean"), 2))
            norm_jac_mean = tf.reduce_mean(
                                tf.reduce_sum(jac_mean_rk2**2, axis=1),
                                name="norm_jac_mean")

            jac_cov = batch_jacobian(cov, x, use_pfor = use_pfor)   # this has shape [?, latent_size, 28, 28, 1]s
            jac_cov_rk2 = tf.reshape(jac_cov, [tf.shape(jac_cov)[0], -1])  # this has shape [?, latent_size*28*28*1]
            # norm_jac_cov = tf.reduce_mean(tf.pow(tf.norm(jac_cov_rk2, axis = 1, name = "norm_jac_cov"), 2))
            norm_jac_cov = tf.reduce_mean(
                                tf.reduce_sum(jac_cov_rk2**2, axis=1),
                                name = "norm_jac_cov")

            reg_mean_node = tf.multiply(scale_m,
                                        norm_jac_mean,
                                        name="reg_mean")

            reg_cov_node = tf.multiply(scale_c,
                                       norm_jac_cov,
                                       name="reg_cov")

            return tf.add(reg_mean_node, reg_cov_node, name=name)

    return contractive_regularizer



# def latent_of_reconstruction_regularizer(scale_mean, scale_covariance, norm, batch_size=1000, while_loop=False, use_pfor=False, swap_memory=False, parallel_iterations=1, trick=False, scope=None):
# #def standard_contractive_regularizer(scale_mean, scale_covariance, norm, trick=False, scope=None):
#
#     # Returns a dictionary of functions that can be used to compute the regularizations
#     # to the mean and covariance generated by the encoder
#
#     # x is input to the network
#
#     # input validation
#     if isinstance(scale_mean, numbers.Integral):
#         raise ValueError('scale_mean cannot be an integer: %s' % scale_mean)
#
#     # input validation
#     if isinstance(scale_covariance, numbers.Integral):
#         raise ValueError('scale_covariance cannot be an integer: %s' % scale_covariance)
#
#     #use_pfor = False # if you change this, please notify Luigi
#
#     def regularizer(mean, cov, x, name=None):
#         with tf.name_scope(scope, 'regularizer', [mean, cov, x]) as name:
#             scale_m = tf.convert_to_tensor(scale_mean,
#                                          dtype=mean.dtype.base_dtype,
#                                          name='scale_mean')
#
#             scale_c = tf.convert_to_tensor(scale_covariance,
#                                          dtype=cov.dtype.base_dtype,
#                                          name='scale_covariance')
#
#
#             jac_mean = batch_jacobian(mean, x, use_pfor = use_pfor)   # this has shape [?, latent_size, 28, 28, 1]
#             jac_mean_rk2 = tf.reshape(jac_mean, [tf.shape(jac_mean)[0], -1])  # this has shape [?, latent_size*28*28*1]
#             norm_jac_mean = tf.reduce_mean(tf.pow(tf.norm(jac_mean_rk2, axis = 1, name = "norm_jac_mean"), 2))
#
#             jac_cov = batch_jacobian(cov, x, use_pfor = use_pfor)   # this has shape [?, latent_size, 28, 28, 1]
#             jac_cov_rk2 = tf.reshape(jac_cov, [tf.shape(jac_cov)[0], -1])  # this has shape [?, latent_size*28*28*1]
#             norm_jac_cov = tf.reduce_mean(tf.pow(tf.norm(jac_cov_rk2, axis = 1, name = "norm_jac_cov"), 2))
#
#             reg_mean_node = tf.multiply(scale_m,
#                                         norm_jac_mean,
#                                         name="reg_mean")
#
#             reg_cov_node = tf.multiply(scale_c,
#                                        norm_jac_cov,
#                                        name="reg_cov")
#
#             return tf.add(reg_mean_node, reg_cov_node, name=name)
#
#     return regularizer


def contractive_reg_list(list_regs):
#     import pdb;pdb.set_trace()
    list_func = []
    reg_module = importlib.import_module(__name__)

    for reg_tuple in list_regs:
        reg_name, reg_kwargs = reg_tuple
#         import pdb;pdb.set_trace()
        reg_method = getattr(reg_module, reg_name)
        contr_reg = reg_method(**reg_kwargs)
        list_func.append(contr_reg)
        
    def contractive_regularizer(mean, cov, x, name=None):
#         import pdb;pdb.set_trace()  
        list_nodes = []
        
        for contr_reg in list_func:
            list_nodes.append(contr_reg(mean, cov, x, name=None))
        
        return list_nodes

    return contractive_regularizer





def cos_contractive_regularizer(scale_mean, norm, scope=None):
    # Returns a dictionary of functions that can be used to compute the regularizations
    # to the mean and covariance generated by the encoder

    # x is input to the network

    # input validation
    if isinstance(scale_mean, numbers.Integral):
        raise ValueError('scale_mean cannot be an integer: %s' % scale_mean)
    if isinstance(scale_mean, numbers.Real):
        if scale_mean < 0.:
            raise ValueError('Setting a scale_mean less than 0 on a regularizer: %g' %
                             scale_mean)
        #if scale_mean == 0.:
        #    return lambda _: None

    # # input validation
    # if isinstance(scale_covariance, numbers.Integral):
    #     raise ValueError('scale_covariance cannot be an integer: %s' % scale_covariance)
    # if isinstance(scale_covariance, numbers.Real):
    #     if scale_covariance < 0.:
    #         raise ValueError('Setting a scale_covariance less than 0 on a regularizer: %g' %
    #                          scale_covariance)
        #if scale_covariance == 0.:
        #    return lambda _: None
    # flags = tf.app.flags
    
    use_pfor = False

    def contractive_regularizer(mean, cov, x, name=None):
        with tf.name_scope(scope, 'contractive_regularizer', [mean, cov, x]) as name:
            scale_m = tf.convert_to_tensor(scale_mean,
                                           dtype=mean.dtype.base_dtype,
                                           name='scale_mean')

            # scale_c = tf.convert_to_tensor(scale_covariance,
            #                              dtype=cov.dtype.base_dtype,
            #                              name='scale_covariance')

            # these should do the "trick", I want to fix module and cos angle (scal prod with "ones vector")
            all_axis_but_batch = tuple(range(len(mean.shape)))[1:]
            mean_norm = tf.sqrt(tf.reduce_sum(mean**2, axis=all_axis_but_batch))
            mean_cos = tf.reduce_sum(mean, axis=all_axis_but_batch)/mean_norm
            norm_jac_mean = tf.norm(batch_jacobian(mean_cos, x, use_pfor=use_pfor), ord=norm, name="norm_jac_mean")

            # all_axis_but_batch = tuple(range(len(cov.shape)))[1:]
            # cov_norm = tf.sqrt(tf.reduce_sum(cov**2, axis=all_axis_but_batch))
            # cov_cos = tf.reduce_sum(cov, axis=all_axis_but_batch)/cov_norm
            # norm_jac_cov = tf.norm(batch_jacobian(cov_norm + cov_cos, x, use_pfor=use_pfor), ord=norm, name="norm_jac_cov")

            reg_mean_node = tf.multiply(scale_m,
                                        norm_jac_mean,
                                        name="reg_mean")

            # reg_cov_node = tf.multiply(scale_c,
            #                    norm_jac_cov,
            #                    name="reg_cov")

            tf.summary.scalar(norm_jac_mean.name, norm_jac_mean)
            # tf.summary.scalar(norm_jac_cov.name, norm_jac_cov)

            return reg_mean_node

    return contractive_regularizer
